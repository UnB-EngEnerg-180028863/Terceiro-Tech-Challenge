# ğŸš€ Tech Challenge - Fine-Tuning de Foundation Model

**Aluno:** VinÃ­cius Oliveira Litran Andrade  
**InstituiÃ§Ã£o:** FIAP - PÃ³s-graduaÃ§Ã£o em InteligÃªncia Artificial  (IA para Devs)

---

## ğŸ“œ DescriÃ§Ã£o do Projeto

Este projeto consiste na aplicaÃ§Ã£o de **fine-tuning de um modelo de linguagem** utilizando o dataset **AmazonTitles-1.3MM**, que contÃ©m tÃ­tulos e descriÃ§Ãµes de produtos da Amazon.

O objetivo Ã© treinar o modelo para que, ao receber uma pergunta baseada no tÃ­tulo de um produto, ele consiga gerar uma resposta coerente com base na descriÃ§Ã£o aprendida durante o treinamento.

---

## ğŸ”¥ Justificativa do Modelo

O desafio sugere o uso de foundation models como **Llama**, **Mistral** ou **BERT**.  
Contudo, devido a limitaÃ§Ãµes de hardware local, o modelo utilizado foi o **DistilGPT-2**, uma versÃ£o leve e otimizada do GPT-2.

Essa escolha permite realizar o fine-tuning e a geraÃ§Ã£o de respostas de forma eficiente, sem comprometer a demonstraÃ§Ã£o dos conceitos e prÃ¡ticas fundamentais do desafio.

---

## ğŸ—‚ï¸ Estrutura do Projeto

â”œâ”€â”€ LF-Amazon-1.3M/ # Dataset (trn.json) ğŸ”— [LF-Amazon-1.3M](https://drive.google.com/file/d/12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK/view) 

â”œâ”€â”€ fine_tune_data.csv # Dados preparados para o treino

â”œâ”€â”€ fine_tuned_model/ # Modelo treinado

â”œâ”€â”€ tech_challenge.ipynb # Notebook com todo o cÃ³digo

â”œâ”€â”€ README.md # DocumentaÃ§Ã£o do projeto

---

## âš™ï¸ Pipeline do Projeto

### ğŸ”¹ 1. PrÃ©-processamento dos Dados
- Leitura do arquivo `trn.json`
- Limpeza dos textos (remoÃ§Ã£o de caracteres invÃ¡lidos e espaÃ§os desnecessÃ¡rios)
- CriaÃ§Ã£o dos prompts no formato:  
Pergunta: {title}
Resposta: {content}

- LimitaÃ§Ã£o dos textos para atÃ© **256 tokens**

### ğŸ”¹ 2. Fine-Tuning (Treinamento)
- Modelo utilizado: **DistilGPT-2**
- ParÃ¢metros principais:
- Ã‰pocas: 1
- Batch Size: 8
- Learning Rate: 0.0003
- MÃ¡ximo de tokens: 256
- Processo:
- Treinamento com os prompts gerados
- AvaliaÃ§Ã£o do modelo antes e depois do fine-tuning

### ğŸ”¹ 3. GeraÃ§Ã£o de Respostas
- O usuÃ¡rio fornece uma pergunta baseada no **tÃ­tulo de um produto**
- O modelo retorna uma **resposta coerente com base na descriÃ§Ã£o aprendida**

---

## ğŸ’» Tecnologias Utilizadas

- ğŸ Python
- ğŸ¤— Hugging Face Transformers
- ğŸ¤— Hugging Face Datasets
- ğŸ¼ Pandas
- ğŸ”¥ PyTorch

---

## â–¶ï¸ DemonstraÃ§Ã£o em VÃ­deo

ğŸ¥ Link para o vÃ­deo no YouTube:  
ğŸ‘‰ [Assista aqui](https://www.youtube.com/SEU_VIDEO_AQUI) *(substituir pelo link real)*

---

## ğŸ“‚ Link do RepositÃ³rio

ğŸ”— [Acesse o projeto no GitHub](https://github.com/UnB-EngEnerg-180028863/Terceiro-Tech-Challenge)
